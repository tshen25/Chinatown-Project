{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection through Census API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting census\n",
      "  Downloading census-0.8.24-py3-none-any.whl (11 kB)\n",
      "Collecting us\n",
      "  Downloading us-3.2.0-py3-none-any.whl (13 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jellyfish\n",
      "  Downloading jellyfish-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (325 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.2\n",
      "  Downloading numpy-2.3.3-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/tonyshen/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.5/204.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tonyshen/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, urllib3, tzdata, numpy, jellyfish, idna, charset_normalizer, us, requests, pandas, census\n",
      "Successfully installed census-0.8.24 charset_normalizer-3.4.3 idna-3.10 jellyfish-1.2.0 numpy-2.3.3 pandas-2.3.3 pytz-2025.2 requests-2.32.5 tzdata-2025.2 urllib3-2.5.0 us-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install census us pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from census import Census\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# --- USER CONFIG ---\n",
    "CENSUS_API_KEY = \"827d2bde6c4a712da4432fb6f1e392a040ee9c6b\"   \n",
    "c = Census(CENSUS_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representative Chinatown addresses - core locations for better geocoding\n",
    "chinatowns = {\n",
    "    \"Boston\": \"88 Beach Street, Boston, MA 02111\",\n",
    "    \"New York\": \"70 Bayard Street, New York, NY 10013\",\n",
    "    \"Philadelphia\": \"1001 Race St, Philadelphia, PA 19107\",\n",
    "    \"Washington DC\": \"701 H Street NW, Washington, DC 20001\",\n",
    "    \"Cleveland\": \"2136 Rockwell Ave, Cleveland, OH 44114\",\n",
    "    \"Chicago\": \"2206 S Wentworth Ave, Chicago, IL 60616\",\n",
    "    \"Seattle\": \"668 S King St, Seattle, WA 98104\",\n",
    "    \"Portland\": \"133 NW 4th Avenue, Portland, OR 97209\",\n",
    "    \"Oakland\": \"388 9th St, Oakland, CA 94607\",\n",
    "    \"San Francisco\": \"839 Stockton Street, San Francisco, CA 94108\",\n",
    "    \"Fresno\": \"1001 F St, Fresno, CA 93706\",\n",
    "    \"Los Angeles\": \"727 N Broadway, Los Angeles, CA 90012\",\n",
    "}\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "\n",
    "def geocode_to_tract(address, max_retries=3):\n",
    "    \"\"\"Use Census Geocoder to get tract GEOID for an address.\"\"\"\n",
    "    url = \"https://geocoding.geo.census.gov/geocoder/geographies/onelineaddress\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            params = {\n",
    "                \"address\": address,\n",
    "                \"benchmark\": \"Public_AR_Current\",\n",
    "                \"vintage\": \"Current_Current\",\n",
    "                \"format\": \"json\"\n",
    "            }\n",
    "            r = requests.get(url, params=params, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            \n",
    "            matches = data.get(\"result\", {}).get(\"addressMatches\", [])\n",
    "            if not matches:\n",
    "                print(f\"    No matches found for: {address}\")\n",
    "                return None, None, None\n",
    "                \n",
    "            tract = matches[0][\"geographies\"][\"Census Tracts\"][0]\n",
    "            geoid = tract[\"GEOID\"]\n",
    "            state = tract[\"STATE\"]\n",
    "            county = tract[\"COUNTY\"]\n",
    "            \n",
    "            return geoid, state, county\n",
    "            \n",
    "        except (IndexError, KeyError) as e:\n",
    "            print(f\"    Parse error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"    Request error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "        \n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def fetch_acs5_population(year, state_fips, county_fips, tract):\n",
    "    \"\"\"Fetch total, Asian, and Chinese population from ACS5 for a single tract/year.\"\"\"\n",
    "    try:\n",
    "        # ACS 5-year data variables:\n",
    "        # B01003_001E = Total population\n",
    "        # B02001_005E = Asian alone\n",
    "        # B02015_006E = Chinese alone or in any combination\n",
    "        \n",
    "        try:\n",
    "            # Try with Chinese data first\n",
    "            data = c.acs5.state_county_tract(\n",
    "                (\"B01003_001E\", \"B02001_005E\", \"B02015_006E\"),\n",
    "                state_fips, \n",
    "                county_fips, \n",
    "                tract,\n",
    "                year=year\n",
    "            )\n",
    "            \n",
    "            if data and len(data) > 0:\n",
    "                total_pop = int(data[0].get(\"B01003_001E\", 0))\n",
    "                asian_pop = int(data[0].get(\"B02001_005E\", 0))\n",
    "                chinese_pop = int(data[0].get(\"B02015_006E\", 0))\n",
    "                \n",
    "                return {\n",
    "                    \"year\": year,\n",
    "                    \"source\": \"acs5\",\n",
    "                    \"total_pop\": total_pop,\n",
    "                    \"asian_pop\": asian_pop,\n",
    "                    \"chinese_pop\": chinese_pop,\n",
    "                }\n",
    "            else:\n",
    "                print(f\"    No ACS5 data returned for {year}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            # If Chinese variable not available, try without it\n",
    "            if \"B02015_006E\" in str(e) or \"unknown variable\" in str(e).lower():\n",
    "                print(f\"    Note: Chinese detail not available for {year}, using Asian only\")\n",
    "                data = c.acs5.state_county_tract(\n",
    "                    (\"B01003_001E\", \"B02001_005E\"),\n",
    "                    state_fips, \n",
    "                    county_fips, \n",
    "                    tract,\n",
    "                    year=year\n",
    "                )\n",
    "                \n",
    "                if data and len(data) > 0:\n",
    "                    total_pop = int(data[0].get(\"B01003_001E\", 0))\n",
    "                    asian_pop = int(data[0].get(\"B02001_005E\", 0))\n",
    "                    \n",
    "                    return {\n",
    "                        \"year\": year,\n",
    "                        \"source\": \"acs5\",\n",
    "                        \"total_pop\": total_pop,\n",
    "                        \"asian_pop\": asian_pop,\n",
    "                        \"chinese_pop\": None,\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"    No ACS5 data returned for {year}\")\n",
    "                    return None\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    Error fetching {year}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHINATOWN DEMOGRAPHICS - ACS5 DATA COLLECTION\n",
      "============================================================\n",
      "\n",
      "📍 Processing Boston...\n",
      "  ✓ GEOID: 25025070103\n",
      "    State: 25, County: 025, Tract: 070103\n",
      "    Note: Chinese detail not available for 2010, using Asian only\n",
      "    No ACS5 data returned for 2010\n",
      "    No ACS5 data returned for 2015\n",
      "    ✓ 2020: Pop=559, Asian=170, Chinese=0\n",
      "    ✓ 2023: Pop=647, Asian=209, Chinese=0\n",
      "\n",
      "📍 Processing New York...\n",
      "  ✓ GEOID: 36061002902\n",
      "    State: 36, County: 061, Tract: 002902\n",
      "    Note: Chinese detail not available for 2010, using Asian only\n",
      "    No ACS5 data returned for 2010\n",
      "    No ACS5 data returned for 2015\n",
      "    ✓ 2020: Pop=4,151, Asian=3,451, Chinese=0\n",
      "    ✓ 2023: Pop=3,832, Asian=3,204, Chinese=0\n",
      "\n",
      "📍 Processing Philadelphia...\n",
      "  ✓ GEOID: 42101000200\n",
      "    State: 42, County: 101, Tract: 000200\n",
      "    Note: Chinese detail not available for 2010, using Asian only\n",
      "    ✓ 2010: Pop=1,919, Asian=1,519\n",
      "    ✓ 2015: Pop=2,331, Asian=1,183, Chinese=0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m             chinese_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, Chinese=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpop[\u001b[33m'\u001b[39m\u001b[33mchinese_pop\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pop[\u001b[33m'\u001b[39m\u001b[33mchinese_pop\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    ✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Pop=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpop[\u001b[33m'\u001b[39m\u001b[33mtotal_pop\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Asian=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpop[\u001b[33m'\u001b[39m\u001b[33masian_pop\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mchinese_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         time.sleep(\u001b[32m0.3\u001b[39m)  \u001b[38;5;66;03m# Rate limiting\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCOLLECTED DATA\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "results = []\n",
    "\n",
    "# ACS5 years only\n",
    "years = [2010, 2015, 2020, 2023]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CHINATOWN DEMOGRAPHICS - ACS5 DATA COLLECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for city, addr in chinatowns.items():\n",
    "    print(f\"\\n📍 Processing {city}...\")\n",
    "    geoid, state_fips, county_fips = geocode_to_tract(addr)\n",
    "    \n",
    "    if not geoid:\n",
    "        print(f\"  ❌ Could not find tract for {city}\")\n",
    "        continue\n",
    "\n",
    "    # Extract tract code (last 6 digits)\n",
    "    tract = geoid[-6:]\n",
    "    print(f\"  ✓ GEOID: {geoid}\")\n",
    "    print(f\"    State: {state_fips}, County: {county_fips}, Tract: {tract}\")\n",
    "\n",
    "    for y in years:\n",
    "        pop = fetch_acs5_population(y, state_fips, county_fips, tract)\n",
    "        if pop:\n",
    "            pop[\"city\"] = city\n",
    "            pop[\"tract_geoid\"] = geoid\n",
    "            results.append(pop)\n",
    "            chinese_str = f\", Chinese={pop['chinese_pop']}\" if pop['chinese_pop'] is not None else \"\"\n",
    "            print(f\"    ✓ {y}: Pop={pop['total_pop']:,}, Asian={pop['asian_pop']:,}{chinese_str}\")\n",
    "        time.sleep(0.3)  # Rate limiting\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLLECTED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    # Calculate percentages\n",
    "    df['asian_pct'] = (df['asian_pop'] / df['total_pop'] * 100).round(1)\n",
    "    df['chinese_pct'] = df.apply(\n",
    "        lambda row: round((row['chinese_pop'] / row['total_pop'] * 100), 1) if pd.notnull(row['chinese_pop']) and row['total_pop'] > 0 else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Display full results\n",
    "    display_cols = ['city', 'year', 'total_pop', 'asian_pop', 'chinese_pop', 'asian_pct', 'chinese_pct', 'tract_geoid']\n",
    "    print(df[display_cols].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY BY CITY (Average 2010-2023)\")\n",
    "    print(\"=\"*60)\n",
    "    summary = df.groupby('city').agg({\n",
    "        'total_pop': 'mean',\n",
    "        'asian_pop': 'mean',\n",
    "        'asian_pct': 'mean'\n",
    "    }).round(0)\n",
    "    summary.columns = ['Avg Total Pop', 'Avg Asian Pop', 'Avg Asian %']\n",
    "    print(summary.sort_values('Avg Asian %', ascending=False).to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRENDS (2010 vs 2023)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get 2010 and 2023 data\n",
    "    df_2010 = df[df['year'] == 2010].set_index('city')\n",
    "    df_2023 = df[df['year'] == 2023].set_index('city')\n",
    "    \n",
    "    if not df_2010.empty and not df_2023.empty:\n",
    "        trends = pd.DataFrame({\n",
    "            '2010 Asian %': df_2010['asian_pct'],\n",
    "            '2023 Asian %': df_2023['asian_pct'],\n",
    "            'Change': df_2023['asian_pct'] - df_2010['asian_pct']\n",
    "        }).round(1)\n",
    "        print(trends.sort_values('Change', ascending=False).to_string())\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('chinatown_demographics.csv', index=False)\n",
    "    print(\"\\n✅ Data saved to chinatown_demographics.csv\")\n",
    "    print(f\"Total records collected: {len(df)}\")\n",
    "else:\n",
    "    print(\"❌ No data collected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
